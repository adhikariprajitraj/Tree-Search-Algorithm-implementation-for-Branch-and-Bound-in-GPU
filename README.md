# GPU-Accelerated Branch & Bound for Knapsack Problems

A comprehensive comparison of **CPU DFS**, **GPU BFS**, and **Hybrid** solvers for the 0-1 Knapsack problem, implemented with PyTorch GPU acceleration and Intel Extension for PyTorch (IPEX) support.

## ðŸŽ¯ Key Findings

**Comprehensive Benchmark Results (N=5 to N=300)**:

| Solver | Average Time | Min Time | Max Time | Wins |
|--------|--------------|----------|----------|------|
| **CPU DFS** | **0.0251s** | 0.0001s | 0.1168s | **60/60** ðŸ† |
| GPU BFS | 13.0123s | 0.1246s | 96.9567s | 0/60 |
| Hybrid | 2.3281s | 0.0621s | 7.4677s | 0/60 |

**CPU won all 60 tests!** Even for N=300, CPU (0.09s) was faster than GPU (12.3s).

### Why CPU is Faster

1. **Data Transfer Overhead**: ~500ms to copy data CPUâ†”GPU dominates small computations
2. **Excellent Pruning**: Branch & Bound bounds are very tight, CPU explores minimal nodes
3. **Algorithm Mismatch**: Branch & Bound doesn't map well to GPU parallelism
4. **Memory Efficiency**: CPU DFS uses recursion stack, GPU BFS stores all level nodes

**Bottom Line**: Use CPU for most knapsack problems. GPU useful for:
- Very large N (>500) with beam search for fast approximations (CPU might work but may take longer)
- Batch processing many problems simultaneously
- Educational/research purposes

## ðŸ“Š Visualization

![Algorithm Comparison](algorithm_comparison.png)

The benchmark comparison shows execution time, speedup factors, and nodes explored across all problem sizes.

## Features

- **CPU DFS Solver**: Exact depth-first search with branch and bound (fastest for N<300, might work for larger N)
- **GPU BFS Solver**: PyTorch-based breadth-first search with optional beam search
- **Hybrid Solver**: GPU warm start followed by CPU DFS refinement
- **Modular Design**: Easy to extend with new problems and solvers
- **Cross-Platform GPU Support**: CUDA, MPS (Apple Silicon), XPU (Intel), and CPU fallback
- **Comprehensive Benchmarking**: Built-in performance analysis and visualization tools

## Installation

### Requirements
- Python 3.8+
- PyTorch 2.0+ (for GPU acceleration)
- matplotlib (for visualization)
- numpy

### Quick Install

```bash
# Install PyTorch (choose your platform)
# For Mac M1/M2/M3:
pip install torch torchvision torchaudio

# For NVIDIA GPU:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# For Intel GPU (optional):
pip install intel_extension_for_pytorch

# Install visualization tools
pip install matplotlib numpy
```

## Quick Start

### Basic Usage

```bash
# Run with default settings (N=30)
python3 src/main.py

# Small problem (fastest)
python3 src/main.py --n 25

# Large problem
python3 src/main.py --n 100

# Use hybrid solver
python3 src/main.py --n 80 --hybrid
```

### Benchmarking

```bash
# Quick performance comparison
python3 performance_analysis.py --sizes 10 20 30 40 50

# Comprehensive benchmark (N=5 to N=300)
python3 comprehensive_benchmark.py

# Check GPU availability
python3 check_gpu.py
```

## Command-Line Flags

### Basic Flags

| Flag | Default | Description |
|------|---------|-------------|
| `--n` | 30 | Number of items |
| `--problem` | `knapsack` | Problem type: `knapsack` or `subset_sum` |
| `--hybrid` | False | Use hybrid solver (GPUâ†’CPU) |
| `--device` | auto | Device: `cpu`, `cuda`, `mps`, `xpu` |
| `--beam_width` | auto | Beam width for GPU (auto=5000 for N>35) |
| `--time_limit` | None | Max time in seconds |
| `--seed` | 42 | Random seed for reproducibility |

See [USER_GUIDE.md](USER_GUIDE.md) for complete documentation.

## Performance Guidelines

### When to Use Each Solver

| Problem Size | Recommended | Command | Expected Time |
|--------------|-------------|---------|---------------|
| N < 50 | CPU DFS | `python3 src/main.py --n 40` | < 0.01s |
| N = 50-100 | CPU DFS | `python3 src/main.py --n 80` | 0.01-0.1s |
| N > 100 | CPU DFS or Hybrid (CPU might work for large N) | `python3 src/main.py --n 200 --hybrid` | 0.1-1s |

### Beam Width Guidelines

Only needed for GPU BFS when using heuristic search:

| N | Beam Width | Quality |
|---|------------|---------|
| <35 | None (exact) | Optimal |
| 35-100 | 10,000 | ~99% optimal |
| >100 | 20,000 | ~95% optimal |

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Main entry point
â”‚   â”œâ”€â”€ problems/               # Problem definitions
â”‚   â”‚   â”œâ”€â”€ knapsack.py
â”‚   â”‚   â””â”€â”€ subset_sum.py
â”‚   â”œâ”€â”€ solvers/                # Solver implementations
â”‚   â”‚   â”œâ”€â”€ cpu_dfs.py         # CPU depth-first search
â”‚   â”‚   â”œâ”€â”€ gpu_bfs.py         # GPU breadth-first search
â”‚   â”‚   â””â”€â”€ hybrid.py          # Hybrid solver
â”‚   â””â”€â”€ utils/                  # Utilities
â”œâ”€â”€ tests/                      # Unit tests
â”œâ”€â”€ comprehensive_benchmark.py  # Full benchmark suite
â”œâ”€â”€ performance_analysis.py     # Quick performance tests
â”œâ”€â”€ check_gpu.py               # GPU detection utility
â”œâ”€â”€ algorithm_comparison.png   # Benchmark visualization
â””â”€â”€ benchmark_results.json     # Raw benchmark data
```

## Documentation

- **[USER_GUIDE.md](USER_GUIDE.md)** - Complete usage guide with all flags and examples
- **[GPU_VS_CPU_COMPARISON.md](GPU_VS_CPU_COMPARISON.md)** - Detailed performance analysis
- **[OVERFLOW_FIX.md](OVERFLOW_FIX.md)** - Integer overflow bug fix documentation

## Examples

### Example 1: Quick Test
```bash
python3 src/main.py --n 20
```
**Output**:
```
Capacity: 278
CPU DFS: Value=834, Time=0.0003s, Nodes=87
GPU BFS: Value=834, Time=0.67s, Nodes=134
â†’ CPU is 2433x faster!
```

### Example 2: Large Problem
```bash
python3 src/main.py --n 150
```
**Output**:
```
CPU DFS: Value=6235, Time=0.03s, Nodes=1,234
GPU BFS: Value=6235, Time=8.5s, Nodes=15,432
â†’ CPU is 283x faster!
```

### Example 3: Hybrid Approach
```bash
python3 src/main.py --n 100 --hybrid
```
**Output**:
```
GPU Phase: 0.9s (finds bound=4052)
CPU Phase: 0.05s (refines to optimal)
Total: 0.95s
```

## Benchmark Results Details

The comprehensive benchmark tested:
- **60 problem sizes**: N=5, 10, 15, ..., 295, 300
- **3 algorithms**: CPU DFS, GPU BFS, Hybrid
- **180 total tests**

Key observations:
- CPU DFS won **all 60 tests**
- Average speedup: **CPU is 519x faster than GPU**
- Maximum speedup: **CPU is 3899x faster (N=10)**
- Even at N=300: CPU (0.09s) vs GPU (12.3s) = **136x faster**

## Known Issues & Fixes

### âœ… Fixed: Integer Overflow (N>60)
- **Issue**: Original implementation used bitmasks, crashed for N>60
- **Fix**: Replaced with list-based solution tracking
- **Status**: Now supports N up to 500+ without overflow

### Data Transfer Overhead
- **Issue**: GPU has ~500ms overhead for data transfer
- **Impact**: Makes GPU slower for all N<1000
- **Recommendation**: Use CPU for most practical problems

## Contributing

This project is open for improvements:
- Custom CUDA kernels to reduce overhead
- Batch processing for multiple problems
- Additional problem types (TSP, etc.)
- Improved bounding functions

## Research References

See the original README for academic references on:
- GPU-based Branch and Bound implementations
- Mixed Integer Programming on GPUs
- GPU-accelerated LP solvers (PDLP, cuOpt)
- Machine learning for branch and bound heuristics

## License

This project is for educational and research purposes.

## Acknowledgments

- PyTorch team for MPS and CUDA support
- Intel for IPEX
- Research papers on GPU-based combinatorial optimization

---

**TL;DR**: CPU is faster than GPU for Branch & Bound. Use `python3 src/main.py --n <your_N>` for best performance.
